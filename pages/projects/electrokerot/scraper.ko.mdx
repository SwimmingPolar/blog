---
title: ElectroKerot 소개
description: ElectroKerot 프로젝트 개발기 - 스크래퍼
keywords: '프로젝트, 프론트엔드, 백엔드, 서버, DB, react, nest.js, next.js, docker, 크롤링, 스크래핑, 포트폴리오'
---

# Electrokerot 스크래퍼

import {
  JsonFormatter,
  Tree,
  Folder,
  File,
  Screenshot,
  Video
} from '@/components'

import InfraScreenshot from '/public/pages/projects/electrokerot/scraper/infra.png'
import FlowChartScreenshot from '/public/pages/projects/electrokerot/scraper/flowchart.png'
import ScraperStructureScreenshot from '/public/pages/projects/electrokerot/scraper/scraper-structure.png'
import '@code-hike/mdx/dist/index.css'

서비스 기획과 함께 어떤 데이터를 어디서 수집하느냐도 중요했습니다. 만약 데이터가 없다면 애초에 불가능한 서비스이기 때문입니다.
데이터를 어떻게 수집하느냐도 문제이고 법적인 문제도 있었습니다. 저작권 법률 상담과 함께 어떤 식으로 데이터를 수집할지 고민했습니다.
대규모 데이터를 지속 가능하게 수집하기 위해선 대상이 되는 상용 서버에 무리가 안 가게 그리고 지속적인 수집을 알아차리지 못하게 해야 했습니다.

단순한 API가 아닌 대규모 데이터 수집은 처음이라, 어떻게 프로그램을 짜야 하는지 조차 감이 잡히지 않았습니다. 그래서
스크래핑 프로그램의 플로우차트를 그려보고, 어떤 식으로 데이터를 수집할지 고민했고, 이를 토대로 프로그램을 짰습니다.

하나의 프로그램으로 모든 과정을 처리하지 않았던 이유에는

- 수집할 데이터의 범위는?
- 중간에 만약 프로그램이 멈춘다면?
- 속도 조절은 어떻게 할 것인가?
- 데이터를 어떻게 저장할 것인가?
- 수집한 데이터가 저장되기 전에 프로그램이 멈추면?
- `css selector`를 통해 naive하게 데이터를 수집하는데 `selector`가 바뀐다면?

등등 여러 변수가 생각났었는데, 이를 모두 한 프로그램에서 처리하려고 하니 너무 복잡해지고, 유지보수가 어려워질 것으로 생각했기 때문입니다.
하나의 기능을 여러 파이프라인으로 나눠 복잡한 과정은 해결했지만, 현재에도 데이터 수집 자체를 `css selector`를 통하기 때문에
변화에 취약하다는 문제가 있습니다.

## 1. 스크래퍼 인프라

<Screenshot alt="인프라" src={InfraScreenshot} caption="인프라" />

스크래퍼를 설계할 때, 다음과 같은 목표로 설계했습니다.

- 유저가 API통신을 요청할 때, 최신의 데이터를 제공한다.
- 주기적으로 데이터를 스크래핑한다.

스크래퍼는 데이터 수집 목적도 있지만 백엔드에 붙어서 하나의 작은 마이크로 서비스로
작동하게끔 설계하려고 했었습니다. 그래서 현재 그림에서 스크래퍼는 백엔드와 동일한 인프라를 사용하고 있습니다.

API 요청이 들어오면, 백엔드에서 내부 마이크로 서비스로 요청을 보냅니다. 해당 서비스는
실시간으로 데이터를 스크래핑하고 저장합니다. 저장된 데이터를 바탕으로 응답을 보내줍니다.

여기서 비효율적일 거라고 생각되는 부분이 보이기 시작했습니다.

- 만약 방금 요청한 데이터가 아직 스크래핑이 안 되었다면, 사용자 요청은 스크래핑이 끝날 때까지 기다려야 한다.
  중복으로 스크래핑하면 리소스 낭비이기 때문이다. 하지만 언제 완료될지 모르기 때문에,
  같은 요청을 보낸 사용자 리스트 중, 큐의 중간에 있는 사용자는 제일 많은 대기시간을 가지게 된다.
- 데이터를 실시간으로 스크래핑한다고 해도, 만약 온라인에 존재하는 데이터가 실시간이 아니라면?
  판매자가 상품의 가격을 업데이트하는 시간이 정해져 있지 않기 때문에 실시간으로
  스크래핑을 한다고 해도, 실시간이 아닐 수 있다.

이 같은 이유에서 서비스로 작동하게끔 하려고 했던 계획을 변경했습니다. 스크래퍼는 백엔드와 동일한 인프라를 사용하지 않고,
스크래핑을 위한 인프라가 따로 존재하게 됩니다.

import InfraModifiedScreenshot from '/public/pages/projects/electrokerot/scraper/infra-modified.png'

<Screenshot
  alt="변경된 인프라"
  src={InfraModifiedScreenshot}
  caption="변경된 인프라"
/>

이렇게 변경될 예정입니다. `docker-swarm`과 `docker`를 사용했던 이유가 스크래퍼 서비스의 인스턴스를
유지하기 위해서였는데, 스크래퍼 서비스가 사라졌으니 `docker-swarm`과 `docker`를 사용할 필요가 없어졌습니다.
이 또한, 변경될 예정입니다.

## 2. 스크래퍼 구조

<a
  href="https://viewer.diagrams.net/?tags=%7B%7D&highlight=0000ff&edit=_blank&layers=1&nav=1&title=Scraping%20flow%20chart#Uhttps%3A%2F%2Fdrive.google.com%2Fuc%3Fid%3D1QKOj0Od5V-5mTXua15tJBE6SeQEo2Lpr%26export%3Ddownload"
  target="_black"
>
  <Screenshot alt="플로우차트" src={FlowChartScreenshot} caption="플로우차트" />
</a>

<Screenshot
  alt="스크래퍼 구조"
  src={ScraperStructureScreenshot}
  caption="스크래퍼 구조"
/>

처음엔 마이크로 서비스와 스크래핑을 모두 해줄 스크래퍼를 만들려고 했기 때문에 스크래퍼의 구조가
다음과 같이 나눠져있었습니다. 물론 구조 자체가 복잡해 나누어서 작성한 것도 있습니다.

<details>
  <summary>Scraper</summary>

단일 프로세스 엔트리 포인트, json 설정 파일을 파싱하여 스크래핑을 준비합니다.

```js scrapConfig.json
{
  "pageBaseUrl": "https://prod.danawa.com/list/?cate=",
  "itemBaseUrl": "https://prod.danawa.com/info/?pcode=",
  "minimumDate": "2018",
  "ignoreWords": ["채굴", "마이닝", "중고"],
  "itemsCategories": [
    "cpu",
    "motherboard",
    "memory",
    "graphics",
    "hdd",
    "ssd",
    "power",
    "case",
    "cooler"
  ],
  "categories": [
    {
      "category": "cpu",
      "categoryNumber": "112747",
      "start": "1",
      "end": "*",
      "ignoreWords": ["해외구매"],
      "filters": [
        {
          "name": "제조사: 인텔",
          "type": "maker",
          "value": "3156"
        },
        {
          "name": "제조사: AMD",
          "type": "maker",
          "value": "3132"
        }
      ]
    },
    {
      "category": "motherboard",
      "categoryNumber": "112751",
      "start": "1",
      "end": "*",
      "filters": [
        {
          "name": "인텔 CPU 전용",
          "type": "attribute",
          "value": "2153"
        },
        {
          "name": "AMD CPU 전용",
          "type": "attribute",
          "value": "2154"
        }
      ]
    },
    {
      "category": "memory",
      "categoryNumber": "112752",
      "start": "1",
      "end": "*",
      "filters": [
        {
          "name": "데스크탑 전용",
          "type": "attribute",
          "value": "1223"
        }
      ]
    },
    {
      "category": "graphics",
      "categoryNumber": "112753",
      "start": "1",
      "end": "*",
      "filters": [
        {
          "name": "NVIDIA 칩셋",
          "type": "attribute",
          "value": "3518"
        },
        {
          "name": "AMD 칩셋",
          "type": "attribute",
          "value": "3517"
        }
      ]
    },
    {
      "category": "ssd",
      "categoryNumber": "112760",
      "start": "1",
      "end": "*",
      "filters": [
        {
          "name": "데스크탑 전용",
          "type": "attribute",
          "value": "636719"
        }
      ]
    },
    {
      "category": "hdd",
      "categoryNumber": "112763",
      "start": "1",
      "end": "*",
      "minimumDate": "0",
      "filters": [
        {
          "name": "데스크탑 전용",
          "type": "attribute",
          "value": "4393"
        }
      ]
    },
    {
      "category": "case",
      "categoryNumber": "112775",
      "start": "1",
      "end": "*",
      "filters": [
        {
          "name": "ATX",
          "type": "attribute",
          "value": "5112"
        },
        {
          "name": "M-ATX",
          "type": "attribute",
          "value": "153734"
        },
        {
          "name": "RTX",
          "type": "attribute",
          "value": "131810"
        },
        {
          "name": "미니 ITX",
          "type": "attribute",
          "value": "5115"
        },
        {
          "name": "튜닝 케이스",
          "type": "attribute",
          "value": "5116"
        }
      ]
    },
    {
      "category": "power",
      "categoryNumber": "112777",
      "start": "1",
      "end": "*",
      "filters": [
        {
          "name": "ATX 파워",
          "type": "attribute",
          "value": "5529"
        },
        {
          "name": "M-ATX 파워",
          "type": "attribute",
          "value": "5530"
        }
      ]
    },
    {
      "category": "cooler",
      "categoryNumber": "11236855",
      "start": "1",
      "end": "*",
      "filters": [
        {
          "name": "CPU 쿨러",
          "type": "attribute",
          "value": "4015"
        },
        {
          "name": "시스템 쿨러",
          "type": "attribute",
          "value": "4017"
        },
        { "name": "3RSYS", "type": "maker", "value": "94456" },
        { "name": "ALPHACOOL", "type": "maker", "value": "43489745" },
        { "name": "ARCTIC", "type": "maker", "value": "45196" },
        { "name": "ASRock", "type": "maker", "value": "4503" },
        { "name": "ASUS", "type": "maker", "value": "2869" },
        { "name": "BRAVOTEC", "type": "maker", "value": "57038" },
        { "name": "CORSAIR", "type": "maker", "value": "4127" },
        { "name": "COUGAR", "type": "maker", "value": "28016" },
        { "name": "darkFlash", "type": "maker", "value": "15938410" },
        { "name": "DEEPCOOL", "type": "maker", "value": "51853" },
        { "name": "EVGA", "type": "maker", "value": "5408" },
        { "name": "FSP", "type": "maker", "value": "4450" },
        { "name": "G.SKILL", "type": "maker", "value": "4130" },
        { "name": "GIGABYTE", "type": "maker", "value": "3148" },
        { "name": "JONSBO", "type": "maker", "value": "117525" },
        { "name": "MSI", "type": "maker", "value": "2904" },
        { "name": "NOCTUA", "type": "maker", "value": "32727" },
        { "name": "NZXT", "type": "maker", "value": "32917" },
        { "name": "PCCOOLER", "type": "maker", "value": "90587" },
        { "name": "SilverStone", "type": "maker", "value": "5738" },
        { "name": "Thermalright", "type": "maker", "value": "3210" },
        { "name": "대양케이스", "type": "maker", "value": "91704" },
        { "name": "리안리", "type": "maker", "value": "4192" },
        { "name": "마이크로닉스", "type": "maker", "value": "3160" },
        { "name": "맥스엘리트", "type": "maker", "value": "105703" },
        { "name": "시스기어", "type": "maker", "value": "112539" },
        { "name": "싸이오닉", "type": "maker", "value": "41818805" },
        { "name": "써멀테이크", "type": "maker", "value": "3186" },
        { "name": "써모랩", "type": "maker", "value": "22601" },
        { "name": "앱코", "type": "maker", "value": "2108" },
        { "name": "에너맥스", "type": "maker", "value": "3851" },
        { "name": "이엠텍", "type": "maker", "value": "4527" },
        { "name": "인텔", "type": "maker", "value": "3156" },
        { "name": "잘만", "type": "maker", "value": "3157" },
        { "name": "쿨러마스터", "type": "maker", "value": "3134" }
      ]
    }
  ]
}
```

</details>

<details>
  <summary>Updater</summary>

Scraper에서 받은 요청을 Crawler로 보내고, 그 응답을 가지고 db를 업데이트합니다.

</details>

<details>
  <summary>Crawler</summary>

받은 요청에 따라 스크래핑 후 데이터를 재단하여 리턴합니다. 인스턴스의 네트워크가 `tor`를
통해 이루어지기 때문에, 익명화가 되어있습니다.

</details>

각각의 `docker` 인스턴스 수를 조절해 스크래핑 속도를 조절할 수 있습니다.
`Updater`와 `Crawler`가 현재 상태에서 한 번에 처리할 수 있는 요청도 정해져 있기 때문에,
해당 비율에 따라 인스턴스 수를 조절하는 것이 효율적입니다.

## 3. 실행 방법

스크래퍼는 총 다음과 같은 프로세스가 실행되어야 합니다.

- MongoDB
- Redis
- Scraper
- Updater
- Crawler
- Tor

이렇게 동시에 실행해야 하는 프로세스들이 많기 때문에 하나하나 실행하기에는 번거로웠습니다.
그래서 스크립트를 통해 한 번에 실행할 수 있도록 만들었습니다.

<details>
  <summary>build-push-deploy.sh</summary>

```sh build-push-deploy.sh
  #! /bin/bash

  # check local registry status
  wget --no-verbose --tries=1 --spider 127.0.0.1:5000/v2/_catalog > /dev/null 2>&1
  if [ $? -eq 4 ]; then
    echo " - Creating local registry service"
    docker service create --name registry --publish 5000:5000 registry:2 2>/dev/null

    if [ $? -ne 0 ]; then
      echo "Failed to create local registry"
      exit 1
    fi
  fi

  # build images
  echo " - Building images"
  docker compose build 2>/dev/null
  if [ $? -ne 0 ]; then
    echo "Build failed"
    exit 1
  fi

  # push images
  echo " - Pushing images"
  docker compose push 2>/dev/null
  if [ $? -ne 0 ]; then
    echo "Push failed"
    exit 1
  fi

  # init docker swarm
  echo " - Initializing docker swarm"
  docker swarm init > /dev/null 2>/dev/null
  if [[ $? != 0 && $? != 1 ]]; then
    echo "Swarm init failed"
    exit 1
  fi

  SERVICE_NAME=collector
  # deploy services
  echo " - Deploying services under stack name: $SERVICE_NAME"
  docker stack deploy -c docker-compose.yml $SERVICE_NAME 2>/dev/null
  if [ $? -ne 0 ]; then
    echo "Deploy failed"
    exit 1
  fi
  echo " - Deployment completed"

  IFS=
  echo "Press Enter to check service status"
  read -s -n 1 key
  if [[ $key = "" ]]; then
    watch -n 1 docker stack services $SERVICE_NAME
  fi
```

</details>

import ScraperDeployScreenshot from '/public/pages/projects/electrokerot/scraper/scraper-deploy.png'
import ScraperStatsScreenshot from '/public/pages/projects/electrokerot/scraper/scraper-stats.png'
import ScraperStandbyScreenshot from '/public/pages/projects/electrokerot/scraper/scraper-standby.png'

<details>
<summary>실행 과정</summary>

**실행**

<Screenshot alt="실행" src={ScraperDeployScreenshot} />

**상태**

<Screenshot alt="상태" src={ScraperStatsScreenshot} />

**대기**

<Screenshot alt="대기" src={ScraperStandbyScreenshot} />

<br />

</details>

<details>
<summary>데이터</summary>

<JsonFormatter />
</details>

## 4. 기타 세부 사항

<details>
<summary>기타 세부 사항</summary>

**스크래핑 속도 조절**

- Updater 인스턴스 수 - 한 번의 트랜잭션으로 업데이트되는 도큐먼트 조절
- Crawler 인스턴스 수 - 스크래핑 속도 조절

Updater와 Crawler 모두 request limiter를 통해 한 번에 처리할 수 있는 요청의 양을 조절할 수 있습니다.

- Updater: (default: 10)
- Crawler (default: 3)

스크래핑을 하는 Crawler의 request limiter를 올리면 IP차단의 가능성이 있음

Updater의 수가 많을수록 업데이트 속도가 빨라지지만, Crawler의 request limiter(default: 3) 때문에 병목이 있으므로, Updater와 Crawler의 전체적인 밸런스가 중요합니다.
토르 네트워크를 우회한 요청의 경우, http 요청 완료에 요청 당 평균 1.5분의 시간이 소요되고 전체 처리 과정의 오버헤드를 고려하여 rest api 요청 처리 시간을 1.75분으로 산정합니다.
이를 기준으로 노드 인스턴스의 수를 적절하게 조절하면 됩니다.

**로컬 환경에서 실행 (개발 환경)**

MongoDB와 Redis가 설치되어 있어야 합니다. Scraper, Updater, Crawler 실행 순서는 상관 없습니다.

`npm run start`

Redis의 경우, 보안 취약점 때문에 기본적인 패스워드가 없을 경우, 실행 후 단시간 내 멀웨어에 감염되기 때문에 패스워드를 설정해야 합니다.

`redis-server —requirepass electrokerot`

어떤 경로로 감염되는지는 모르겠지만 추후 사용하는 도커 이미지들도 권한상승(privilege escalation) 공격에 잠재적으로 노출될 위험이 있는 거 같습니다.

[https://www.trendmicro.com/en_us/research/20/d/exposed-redis-instances-abused-for-remote-code-execution-cryptocurrency-mining.html](https://www.trendmicro.com/en_us/research/20/d/exposed-redis-instances-abused-for-remote-code-execution-cryptocurrency-mining.html)

**도커 환경에서 실행 (실제 스크래핑 환경)**

배포 환경에서는 (NODE_ENV=production) 프록시가 없다면 실행되지 않습니다.

**로컬 컨테이너 레지스트리 생성**

도커 스웜을 사용하기 위해선 레지스트리가 필요함으로, 로컬에 생성해야 합니다.

`docker service create --name registry --publish published=5000,target=5000 registry:2`

**볼륨 생성**

redis 데이터가 보존되며, 서비스 재실행 시 볼륨이나 redis를 초기화해주어야 합니다.

`docker create volume electrokerot-redis`

docker-compose.yml 파일이 있는 위치에서 실행해야 합니다.

**도커 이미지 빌드**

`docker compose build`

**도커 이미지를 로컬 레지스트리로 푸쉬**

`docker compose push`

**도커 스웜 실행**

`docker swarm init`

`docker stack deploy -c docker-compose.yml collector`

스웜이 실행된 후, 스크래핑 속도를 올리기 위해 노드 인스턴스 수를 순서에 맞게 스케일 아웃 해줍니다.

`docker service scale collector_tor=15`

`docker service scale collector_crawler=35`

`docker service scale collector_updater=15`

docker compose 3.0 이상에서 서비스 시작 순서를 보장하는 오케스트레이션 기능이 없어서 수십 개의 replicas를 한 번에 시작하면 서비스가 정상적으로 시작되지 않는 경우가 있습니다.
그래서 적은 수의 인스턴스를 정상적으로 올린 뒤에 스케일링 해야 합니다.

리눅스 환경이나 wsl bash 환경에서 다음 명령어로 서비스 상태를 확인할 수 있습니다.

전체 서비스 상태 확인

`watch -n 1 docker service ls`

`docker service logs collector_scraper`

`docker service logs collector_updater`

`docker service logs collector_crawler`

**실행 환경 사양**

3.6Ghz 8코어 16쓰레드, 32GB 메모리 환경

**속도**

1개의 요청은 1개의 페이지나 1개의 ajax요청으로 생각하고, 8000개의 요청을 완료하는데 대략 2시간 정도 소요됩니다.

</details>
