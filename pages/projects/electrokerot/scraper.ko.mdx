---
title: ElectroKerot 소개
description: ElectroKerot 프로젝트 개발기 - 스크래퍼
keywords: '프로젝트, 프론트엔드, 백엔드, 서버, DB, react, nest.js, next.js, docker, 크롤링, 스크래핑, 포트폴리오'
---

# Electrokerot 스크래퍼

import { Tree, Folder, File, Screenshot, Video } from '@/components'

import InfraScreenshot from '/public/pages/projects/electrokerot/scraper/infra.png'
import FlowChartScreenshot from '/public/pages/projects/electrokerot/scraper/flowchart.png'
import ScraperStructureScreenshot from '/public/pages/projects/electrokerot/scraper/scraper-structure.png'

## 1. 스크래퍼 인프라

<Screenshot alt="인프라" src={InfraScreenshot} caption="인프라" />

스크래퍼를 설계할 때, 다음과 같은 목표로 설계했다.

- 유저가 API통신을 요청할 때, 최신의 데이터를 제공한다.
- 주기적으로 데이터를 스크래핑한다.

스크래퍼는 데이터 수집 목적도 있지만 백엔드에 붙어서 하나의 작은 마이크로 서비스로
작동하게끔 설계하려고 했다.

API 요청이 들어오면, 백엔드에서 내부 마이크로 서비스로 요청을 보낸다. 해당 서비스는
실시간으로 데이터를 스크래핑하고 저장한다. 저장된 데이터를 바탕으로 응답을 보낸다.

여기서 비효율적일 거라고 생각되는 부분이 보이기 시작했다.

- 만약 방금 요청한 데이터가 아직 스크래핑이 안 되었다면, 사용자 요청은 스크래핑이 끝날 때까지 기다려야 한다.
  중복으로 스크래핑하면 리소스 낭비이기 때문이다. 하지만 언제 완료될지 모르기 때문에,
  같은 요청을 보낸 사용자 리스트 중, 큐의 중간에 있는 사용자는 제일 많은 대기시간을 가지게 된다.
- 데이터를 실시간으로 스크래핑한다고 해도, 만약 온라인에 존재하는 데이터가 실시간이 아니라면?
  판매자가 상품의 가격을 업데이트하는 시간이 정해져 있지 않기 때문에 실시간으로
  스크래핑을 한다고 해도, 실시간이 아닐 수 있다.

이 같은 이유에서 서비스로 작동하게끔 하려고 했던 계획을 변경했다.

import InfraModifiedScreenshot from '/public/pages/projects/electrokerot/scraper/infra-modified.png'

<Screenshot
  alt="변경된 인프라"
  src={InfraModifiedScreenshot}
  caption="변경된 인프라"
/>

이렇게 변경될 예정이다. 거기다 `docker-swarm`과 `dockder`를 사용했던 이유가 스크래퍼 서비스의 인스턴스를
유지하기 위해서였는데, 스크래퍼 서비스가 사라졌으니 `docker-swarm`과 `dockder`를 사용할 필요가 없어졌다.
이 또한, 추후 변경될 예정이다.

## 2. 스크래퍼 구조

<Screenshot alt="플로우차트" src={FlowChartScreenshot} caption="플로우차트" />{' '}

<Screenshot
  alt="스크래퍼 구조"
  src={ScraperStructureScreenshot}
  caption="스크래퍼 구조"
/>

처음엔 마이크로 서비스와 스크래핑을 모두 해줄 스크래퍼를 만들려고 했기 때문에 스크래퍼의 구조가
다음과 같이 나눠져있었다. 물론 구조 자체가 복잡해 나누어서 작성한 것도 있다.

<details>
  <summary>Scraper</summary>

단일 프로세스 엔트리 포인트, json 설정 파일을 파싱하여 스크래핑을 준비한다.

</details>

<details>
  <summary>Updater</summary>

Scraper에서 받은 요청을 Crawler로 보내고, 그 응답을 가지고 db를 업데이트한다.

</details>

<details>
  <summary>Crawler</summary>

받은 요청에 따라 스크래핑 후 데이터를 재단하여 리턴한다. 인스턴스의 네트워크가 `tor`를
통해 이루어지기 때문에, 익명화가 되어있다.

</details>

각각의 `docker` 인스턴스 수를 조절해 스크래핑 속도를 조절할 수 있다.
`Updater`와 `Crawler`가 현재 상태에서 한 번에 처리할 수 있는 요청도 정해져 있기 때문에,
해당 비율에 따라 인스턴스 수를 조절하는 것이 효율적이다.

## 3. 기타 세부 사항

<details>
  <summary>기타 세부 사항</summary>

**스크래핑 속도 조절**

- Updater 인스턴스 수 - 한 번의 트랜잭션으로 업데이트되는 도큐먼트 조절
- Crawler 인스턴스 수 - 스크래핑 속도 조절

Updater와 Crawler 모두 request limiter를 통해 한 번에 처리할 수 있는 요청의 양을 조절한다.

- Updater: (default: 10)
- Crawler (default: 3)

스크래핑을 하는 Crawler의 request limiter를 올리면 IP차단의 가능성이 있음

Updater의 수가 많을수록 업데이트 속도가 빨라지지만, Crawler의 request limiter(default: 3) 때문에 병목이 있으므로, Updater와 Crawler의 전체적인 밸런스가 중요하다. 토르 네트워크를 우회한 요청의 경우, http 요청 완료에 요청 당 평균 1.5분의 시간이 소요되고 전체 처리 과정의 오버헤드를 고려하여 rest api 요청 처리 시간을 1.75분으로 산정한다. 이를 기준으로 노드 인스턴스의 수를 적절하게 조절하면 되겠다.

**로컬 환경에서 실행 (개발 환경)**

MongoDB와 Redis가 설치되어 있어야 한다. Scraper, Updater, Crawler 실행 순서는 상관없다.

`npm run start`

Redis의 경우, 보안 취약점 때문에 기본적인 패스워드가 없을 경우, 실행 후 단시간 내 멀웨어에 감염되기 때문에 패스워드 보안을 설정해야 한다.

`redis-server —requirepass electrokerot`

어떤 경로로 감염되는지는 모르겠지만 추후 사용하는 도커 이미지들도 권한상승(privilege escalation) 공격에 잠재적으로 노출될 위험이 있는 거 같다.

[https://www.trendmicro.com/en_us/research/20/d/exposed-redis-instances-abused-for-remote-code-execution-cryptocurrency-mining.html](https://www.trendmicro.com/en_us/research/20/d/exposed-redis-instances-abused-for-remote-code-execution-cryptocurrency-mining.html)

**도커 환경에서 실행 (실제 스크래핑 환경)**

배포 환경에서는 (NODE_ENV=production) 프록시가 없다면 실행되지 않는다.

**로컬 컨테이너 레지스트리 생성**

도커 스웜을 사용하기 위해선 레지스트리가 필요함으로, 로컬에 생성한다.

`docker service create --name registry --publish published=5000,target=5000 registry:2`

**볼륨 생성**

redis 데이터가 보존되며, 서비스 재실행 시 볼륨이나 redis를 초기화해주어야 한다.

`docker create volume electrokerot-redis`

docker-compose.yml 파일이 있는 위치에서 실행해야 한다.

**도커 이미지 빌드**

`docker compose build`

**도커 이미지를 로컬 레지스트리로 푸쉬**

`docker compose push`

**도커 스웜 실행**

`docker swarm init`

`docker stack deploy -c docker-compose.yml collector`

스웜이 실행된 후, 스크래핑 속도를 올리기 위해 노드 인스턴스 수를 순서에 맞게 스케일 아웃 한다.

`docker service scale collector_tor=15`

`docker service scale collector_crawler=35`

`docker service scale collector_updater=15`

docker compose 3.0 이상에서 서비스 시작 순서를 보장하는 오케스트레이션 기능이 없어서 수십 개의 replicas를 한 번에 시작하면 서비스가 정상적으로 시작되지 않는다. 그래서 적은 수의 인스턴스를 정상적으로 올린 뒤에 스케일링 해야 한다.

리눅스 환경이나 wsl bash 환경에서 다음 명령어로 서비스 상태를 확인한다.

전체 서비스 상태 확인

`watch -n 1 docker service ls`

`docker service logs collector_scraper`

`docker service logs collector_updater`

`docker service logs collector_crawler`

**오류**

토르를 우회하는 요청이다 보니 다양한 네트워크 오류가 발생한다. 아직 명확한 이유는 모르겠으며, 한 번 스크래핑 후 남은 목록을 다시 스크래핑하는 방법 밖에는 없어 보인다. 네트워크 오류 외 아직 여러 버그가 존재함

**실행 환경 사양**

3.6Ghz 8코어 16쓰레드, 32GB 메모리 환경

**속도**

1개의 요청은 1개의 페이지나 1개의 ajax요청으로 생각하고, 8000개의 요청을 완료하는데 대략 2시간 정도 걸린다.

</details>
